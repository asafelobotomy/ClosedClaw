# ClawTalk 2.1 Protocol Specification

**Version**: 2.1 â€” "The Internal Language"
**Status**: Draft
**Date**: 2026-02-13
**Based on**: ClawTalk_2.1.png architecture diagram

---

## Table of Contents

1. [Design Philosophy](#1-design-philosophy)
2. [Architecture Overview](#2-architecture-overview)
3. [The Internal Language â€” What It Is and Isn't](#3-the-internal-language)
4. [Layer 1: GTK GUI TranslatorDevice](#4-layer-1-gtk-gui-translatordevice)
5. [Layer 2: ClosedClaw LLM Frontend](#5-layer-2-closedclaw-llm-frontend)
6. [Layer 3: Security Checkpoint #Inbound](#6-layer-3-security-checkpoint-inbound)
7. [Layer 4: SubAgent Pool](#7-layer-4-subagent-pool)
8. [Layer 5: Security Checkpoint #Outbound](#8-layer-5-security-checkpoint-outbound)
9. [CT/1 Wire Format](#9-ct1-wire-format)
10. [CT/1 and MCP Coexistence](#10-ct1-and-mcp-coexistence)
11. [ClawTalk Compressed English Spec](#11-clawtalk-compressed-english-spec)
12. [.claws Skill Files](#12-claws-skill-files)
13. [Semantic Response Cache](#13-semantic-response-cache)
14. [Token Budget Analysis](#14-token-budget-analysis)
15. [Implementation Mapping](#15-implementation-mapping)
16. [Risks and Mitigations](#16-risks-and-mitigations)
17. [Phased Roadmap](#17-phased-roadmap)

---

## 1. Design Philosophy

### The Question

> Is there a form of communication â€” not English, but already established in all LLMs â€” that achieves comparable understanding, better efficiency, and fewer tokens than what we currently use?

### The Answer

**No single alternative encoding beats English for LLM comprehension when measured against current tokenizers.** English is the efficiency baseline by design â€” tokenizers were literally optimized for it. Every other encoding (Chinese characters, binary, emoji, math notation, Esperanto) performs worse on at least one of: token count, comprehension quality, or ambiguity.

However, **English as people write it is wildly inefficient.** The average user message contains:

| Waste Category      | Example                              | Token Cost             |
| ------------------- | ------------------------------------ | ---------------------- |
| Politeness          | "Could you please..."                | 3-5 tokens per message |
| Redundant structure | "and then provide me with a..."      | 5-8 tokens             |
| Ambiguity padding   | "something like", "sort of", "maybe" | 2-4 tokens             |
| Reformulation       | Saying the same thing two ways       | 10-20 tokens           |
| Filler              | "Well, basically, I was thinking..." | 5-10 tokens            |

A 50-token user message typically contains 15-25 tokens of pure intent and 25-35 tokens of human conversational padding.

### The ClawTalk 2.1 Strategy

ClawTalk 2.1 is **not a new language**. It is:

1. **A structured protocol envelope** (CT/1 wire format) for machine-parseable metadata â€” routing, security annotations, priorities, references
2. **A telegraphic English register** for semantic content â€” compressed natural English that removes all waste while preserving full LLM comprehension
3. **A shorthand dictionary** for the 50 most common terms in the ClosedClaw domain â€” abbreviations LLMs already understand (e.g., `ctx` â†’ context, `cfg` â†’ config, `auth` â†’ authentication)
4. **A transport-only optimization** â€” the LLM **never sees the wire format**. ClawTalk compresses on the wire between components; each component receives clean, expanded natural language.

This achieves:

- **~30% token savings** over natural conversational English per message
- **~60-70% savings** on structured inter-agent messages (CT/1 protocol messages)
- **Zero comprehension degradation** â€” every token the LLM receives is standard English
- **Zero new decoding logic** â€” no LLM needs to "learn" ClawTalk
- **Zero latency overhead** â€” encoding/decoding is pure string manipulation (<1ms)

---

## 2. Architecture Overview

The full pipeline from the ClawTalk_2.1.png diagram, mapped to concrete components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER (English)                              â”‚
â”‚                                                                     â”‚
â”‚  "Can you search for the latest Node.js security vulnerabilities    â”‚
â”‚   and give me a summary of the critical ones from the last month?"  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: GTK GUI TranslatorDevice                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                 â”‚
â”‚  Location: extensions/gtk-gui/                                      â”‚
â”‚                                                                     â”‚
â”‚  1. Receives user English                                           â”‚
â”‚  2. Strips conversational waste (rules-based, <1ms, no LLM call)   â”‚
â”‚  3. Attaches structured metadata envelope                           â”‚
â”‚  4. Outputs: CT/1 message + compressed English payload              â”‚
â”‚                                                                     â”‚
â”‚  OUTPUT:                                                            â”‚
â”‚  CT/1 REQ web_search q="nodejs security vuln" since=30d             â”‚
â”‚       filter=critical limit=5                                       â”‚
â”‚  ---                                                                â”‚
â”‚  {"user_intent": "search nodejs CVEs, critical, past month,         â”‚
â”‚    summarize results"}                                              â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2: ClosedClaw LLM Frontend                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                    â”‚
â”‚  Location: src/agents/ (pi-embedded-runner + clawtalk hook)         â”‚
â”‚                                                                     â”‚
â”‚  1. Receives CT/1 envelope                                          â”‚
â”‚  2. Parses structured metadata (routing hints, action, params)      â”‚
â”‚  3. Determines intent classification (heuristic, <1ms)              â”‚
â”‚  4. Selects target subagent(s) via Directory                        â”‚
â”‚  5. Compiles relevant .claws skills into NL prompt                  â”‚
â”‚  6. Forwards to Security Checkpoint #Inbound                        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 3: Security Checkpoint #Inbound                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                               â”‚
â”‚  Location: src/agents/clawtalk/kernel-shield.ts                     â”‚
â”‚            + before_agent_start hook                                â”‚
â”‚                                                                     â”‚
â”‚  Three-layer defense:                                               â”‚
â”‚  L1: Structural â€” permission check vs .claws manifest (Block 1)    â”‚
â”‚  L2: Semantic â€” risk vector Vr = (P_access Ã— S_data) + (1 âˆ’ T)    â”‚
â”‚  L3: Neural Attestation â€” cosine drift detection (stub, future)    â”‚
â”‚                                                                     â”‚
â”‚  OUTCOMES:                                                          â”‚
â”‚  â”œâ”€ PASS â†’ forward to SubAgent Pool                                 â”‚
â”‚  â”œâ”€ LOG  â†’ forward + log risk telemetry                             â”‚
â”‚  â”œâ”€ BIOMETRIC â†’ require user confirmation, then forward             â”‚
â”‚  â””â”€ BLOCK â†’ reject, return security warning to Frontend LLM        â”‚
â”‚             Frontend LLM responds to user with risk info            â”‚
â”‚             and requests further instructions                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ PASS                         â”‚ BLOCK
            â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 4: SubAgent Pool  â”‚    â”‚  SECURITY ISSUE FOUND    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚    â”‚  Report back to Frontend â”‚
â”‚                           â”‚    â”‚  LLM â†’ user gets risk   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚  info + prompt for       â”‚
â”‚  â”‚Scientistâ”‚ â”‚Current â”‚   â”‚    â”‚  instructions            â”‚
â”‚  â”‚SubAgent â”‚ â”‚Affairs â”‚   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ (IDLE)  â”‚ â”‚SubAgentâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚(ACTIVE)â”‚   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚ Coding  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚SubAgent â”‚ â”‚Calendarâ”‚  â”‚
â”‚  â”‚ (IDLE)  â”‚ â”‚SubAgentâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ (IDLE)  â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”‚  Note   â”‚              â”‚
â”‚  â”‚ Taking  â”‚              â”‚
â”‚  â”‚SubAgent â”‚              â”‚
â”‚  â”‚ (IDLE)  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                           â”‚
â”‚  SubAgent activation:     â”‚
â”‚  - Spawned by Frontend    â”‚
â”‚  - Skills from .claws     â”‚
â”‚  - Tools from manifest    â”‚
â”‚  - Model from escalation  â”‚
â”‚    or skill preference    â”‚
â”‚                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ Result
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 5: Security Checkpoint #Outbound                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â”‚
â”‚  Location: message_sending hook                                     â”‚
â”‚            + kernel-shield evaluation                               â”‚
â”‚                                                                     â”‚
â”‚  Security Model: Scan + Sandbox (no re-prompting)                   â”‚
â”‚                                                                     â”‚
â”‚  1. Rules-based scan (<1ms, no LLM call):                           â”‚
â”‚     - Embedded instruction detection (prompt injection)             â”‚
â”‚     - Sensitive data leakage (PII, credentials, internal paths)     â”‚
â”‚     - Content policy violations                                     â”‚
â”‚     - Anomalous patterns (unexpected data exfil)                    â”‚
â”‚                                                                     â”‚
â”‚  2. Structural enforcement (pre-existing):                          â”‚
â”‚     - SubAgent ran in isolated session (separate context)           â”‚
â”‚     - Tool access restricted by .claws manifest                     â”‚
â”‚     - Docker/WASM sandbox for untrusted execution                   â”‚
â”‚                                                                     â”‚
â”‚  OUTCOMES:                                                          â”‚
â”‚  â”œâ”€ CLEAN â†’ pass through to Frontend LLM                            â”‚
â”‚  â””â”€ CONCERN â†’ block response, forward risk assessment               â”‚
â”‚               to Frontend LLM for user delivery                     â”‚
â”‚               (user sees: risk warning + guidance)                  â”‚
â”‚                                                                     â”‚
â”‚  Also strips ALL ClawTalk artifacts from response:                  â”‚
â”‚  - CT/1 headers, ClawDense opcodes, routing annotations             â”‚
â”‚  - Subagent handoff markers, dense sigils                           â”‚
â”‚  - User NEVER sees protocol internals                               â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2 (Return): ClosedClaw LLM Frontend                         â”‚
â”‚                                                                     â”‚
â”‚  1. Receives clean NL result from outbound checkpoint               â”‚
â”‚  2. Integrates into conversation context                            â”‚
â”‚  3. May add conversational framing for user                         â”‚
â”‚  4. Forwards to GTK GUI TranslatorDevice                            â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1 (Return): GTK GUI TranslatorDevice                        â”‚
â”‚                                                                     â”‚
â”‚  1. Receives clean NL from Frontend LLM                             â”‚
â”‚  2. Final artifact scrub (defense in depth)                         â”‚
â”‚  3. Renders to user in natural English                              â”‚
â”‚                                                                     â”‚
â”‚  OUTPUT TO USER:                                                    â”‚
â”‚  "Here are the 5 most critical Node.js security vulnerabilities     â”‚
â”‚   from the past month: ..."                                         â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. The Internal Language

### What It Is

ClawTalk's "Internal LLM Language" is a **three-component hybrid**:

#### Component A: CT/1 Wire Protocol (Machine-Readable Envelope)

Used **between components** on the wire. Never seen by the LLM.

```
CT/1 REQ web_search q="nodejs vuln" since=30d filter=critical limit=5
```

This is a structured command protocol â€” similar to HTTP or Redis commands. It tells the system **what to do** with zero ambiguity. Every LLM understands similar structures from training on code, CLI tools, and API documentation, but in ClawTalk 2.1 the LLM doesn't need to â€” it's purely a transport format parsed by code.

**Token cost**: ~15 tokens for the above. Equivalent English: ~55 tokens. **Saving: 73%.**

#### Component B: Telegraphic English (Human-Readable Content)

Used for **semantic content** â€” the actual meaning the user wants to communicate. This is what the LLM actually reads.

| Full English                                                                                                         | Telegraphic English                           | Saving |
| -------------------------------------------------------------------------------------------------------------------- | --------------------------------------------- | ------ |
| "Could you please search for information about climate change and provide me with a summary in bullet point format?" | "search climate change, bullet summary"       | 70%    |
| "Write me a Python function that sorts a list by the second element of each tuple"                                   | "python func: sort list by tuple 2nd element" | 45%    |
| "Check if there are any new security vulnerabilities in our dependencies and let me know about anything critical"    | "check dep vulns, report critical"            | 65%    |

Rules for telegraphic conversion:

1. Drop articles (a, an, the) â€” LLMs don't need them for comprehension
2. Drop politeness (please, could you, would you mind) â€” zero semantic value
3. Drop reformulation (in other words, that is to say) â€” one statement suffices
4. Drop hedging (maybe, sort of, kind of, I think) â€” be direct
5. Use common abbreviations (func, dep, vuln, auth, cfg, ctx) â€” all in LLM training data
6. Preserve all domain nouns, verbs, and modifiers â€” these carry meaning
7. Preserve word order â€” English word order is how LLMs parse intent

**This is not a new language.** It's a style guide for writing English with maximum information density. Every word is already in every LLM's vocabulary. No translation or decoding is needed.

#### Component C: Domain Shorthand Dictionary

A fixed set of ~50 abbreviations for ClosedClaw's most common terms:

```json5
{
  // Routing & System
  ctx: "context",
  cfg: "config / configuration",
  auth: "authentication / authorization",
  sess: "session",
  gw: "gateway",
  req: "request",
  res: "response",
  cb: "callback",
  ack: "acknowledge",

  // Paths (transport only â€” not in LLM prompts)
  "src/sec": "src/security",
  "src/ag": "src/agents",
  "src/gw": "src/gateway",
  "src/cfg": "src/config",
  "src/rt": "src/routing",
  "ext/": "extensions/",

  // Severity & Priority
  crit: "critical",
  hi: "high priority",
  lo: "low priority",

  // Actions
  dep: "dependency / dependencies",
  vuln: "vulnerability / vulnerabilities",
  impl: "implementation / implement",
  exec: "execute / execution",
  fmt: "format",
  gen: "generate",
  init: "initialize",
  iter: "iterate / iteration",
  tok: "token / tokens",
  ver: "version",
  val: "validate / validation",
  perms: "permissions",
  env: "environment",
  err: "error",
  ret: "return",
  fn: "function",
  param: "parameter",
  repo: "repository",
  dir: "directory",
  proc: "process",
  sys: "system",
  info: "information",
  prev: "previous",
  curr: "current",
  tmp: "temporary",
  max: "maximum",
  min: "minimum",
  avg: "average",
  num: "number",
  str: "string",
  bool: "boolean",
  obj: "object",
  arr: "array",
  msg: "message",
  ts: "timestamp",
}
```

Every one of these abbreviations appears millions of times in LLM training data (from code, documentation, chat logs, Stack Overflow). LLMs understand `fn` as well as `function`, `ctx` as well as `context`. Zero comprehension risk.

### What It Isn't

- **Not a cipher or encoding** â€” no binary, hex, base64, or Unicode tricks
- **Not a constructed language** â€” no Esperanto, no invented grammar
- **Not a symbolic system** â€” no emoji, math notation, or special characters as semantic carriers
- **Not a compression algorithm** â€” no lossy or lossless data compression
- **Not something the LLM decodes** â€” the LLM reads normal English words; the system handles the protocol envelope

### Why Every Alternative Fails

| Candidate                         | Why It Fails                                                              | Token Efficiency vs English |
| --------------------------------- | ------------------------------------------------------------------------- | --------------------------- |
| Chinese characters                | Multi-byte UTF-8 â†’ 1-2 tokens per character; reasoning quality drops      | **Worse**                   |
| Mathematical notation             | Unicode math symbols cost 2-3 tokens each; can't express general concepts | **Worse**                   |
| Binary / Hex / Base64             | "hello" = 1 token; in binary = 15-20 tokens                               | **Much worse**              |
| Emoji                             | ðŸ” costs 2-3 tokens; ambiguous (ðŸŒ = world? earth? travel?)               | **Worse + ambiguous**       |
| JSON                              | Syntax overhead (quotes, braces, colons) wastes tokens                    | **~15% worse**              |
| Esperanto / Constructed languages | Multi-byte chars, lower training data volume, comprehension drops         | **Worse**                   |
| LLM-invented protocols            | No weight updates possible; distribution shift degrades comprehension     | **Catastrophically worse**  |
| **Telegraphic English + CT/1**    | **Same tokenizer optimization; same vocab; zero waste**                   | **30-70% better**           |

---

## 4. Layer 1: GTK GUI TranslatorDevice

### Purpose

Sits between the user and the ClosedClaw LLM Frontend. Handles two directions:

**Inbound (User â†’ System)**:

1. Accept natural English from the user
2. Strip conversational waste (rules-based, no LLM call, <1ms)
3. Classify intent heuristically (keyword matching)
4. Wrap in CT/1 envelope with routing hints
5. Forward to Frontend LLM

**Outbound (System â†’ User)**:

1. Receive clean NL from Frontend LLM
2. Final artifact scrub (defense in depth)
3. Render to user

### Rules-Based Compression (Inbound)

The GTK GUI applies these transformations **without calling any LLM**:

```
INPUT:  "Hey, could you please search for the latest Node.js security
         vulnerabilities from the past month and give me a summary of
         just the critical ones? Thanks!"

STEP 1 â€” Strip politeness:
         "search for the latest Node.js security vulnerabilities from
          the past month and give me a summary of just the critical ones"

STEP 2 â€” Strip articles & filler:
         "search latest Node.js security vulnerabilities past month,
          give summary critical ones"

STEP 3 â€” Apply domain shorthand:
         "search latest nodejs security vulns past month, summary critical"

STEP 4 â€” Classify intent: web_search (confidence: 0.85)

STEP 5 â€” Build CT/1 envelope:
         CT/1 REQ web_search q="nodejs security vuln" since=30d filter=critical

OUTPUT: CT/1 message with compressed English payload
        Total: ~15 tokens (original: ~45 tokens) â€” 67% savings
```

### Implementation

This maps directly to the existing heuristic encoder at `src/agents/clawtalk/encoder.ts`. The encoder already:

- Runs pattern matching against 15+ intent categories
- Extracts parameters (time windows, limits, URLs, file paths)
- Builds CT/1 wire format
- Completes in <1ms with zero LLM calls

The GTK GUI extension (`extensions/gtk-gui/`) calls this encoder before sending to the gateway.

### What the GUI Does NOT Do

- **Does NOT run a local LLM** for compression â€” that would add latency (seconds) and complexity (GPU/RAM requirements) for marginal savings over rules-based stripping
- **Does NOT alter user intent** â€” domain nouns, verbs, and modifiers pass through unchanged
- **Does NOT handle ambiguity resolution** â€” if the user's intent is unclear, the full (stripped but semantically complete) text goes to the Frontend LLM, which has the reasoning capacity to handle ambiguity

---

## 5. Layer 2: ClosedClaw LLM Frontend

### Purpose

The central orchestrator. Receives CT/1 messages from the GTK GUI, determines what needs to happen, and coordinates the subagent pool.

### Inbound Flow

```
CT/1 REQ web_search q="nodejs security vuln" since=30d filter=critical
                    â”‚
                    â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  CT/1 Parser  â”‚  Parse protocol envelope
           â”‚  (parser.ts)  â”‚  Extract: verb=REQ, action=web_search, params={...}
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Directory    â”‚  Route to subagent based on intent
           â”‚(directory.ts) â”‚  web_search â†’ "Current Affairs SubAgent"
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Skill Compiler   â”‚  Load matching .claws skill files
           â”‚(skill-compiler.ts)â”‚  Compile: Vibe â†’ system prompt
           â”‚                   â”‚           IDL â†’ tool schemas
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Manifest â†’ guardrails
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Escalation Check â”‚  Does this need a more powerful model?
           â”‚  (escalation.ts)  â”‚  Confidence < threshold â†’ escalate to cloud
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  TranslationResultâ”‚  Clean NL system prompt + tool list
           â”‚  (No CT/1 in it!) â”‚  + model override (if escalating)
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  + routing decision (for logging only)
                  â”‚
                  â–¼
           Security Checkpoint #Inbound
```

### Key Design Rule

**The LLM never sees CT/1 protocol syntax.** The Translation Device decompresses the CT/1 envelope into clean natural language before it reaches any LLM context. The subagent receives something like:

```
System: You are a research specialist. Search the web for Node.js security
        vulnerabilities from the past 30 days. Focus on critical severity.
        Return CVE IDs, severity ratings, affected versions, and mitigations.
        Maximum 5 results.
```

This is compiled from the CT/1 parameters + the subagent's `.claws` skill file. It's plain English. The LLM processes it exactly as it would process any instruction.

---

## 6. Layer 3: Security Checkpoint #Inbound

### Purpose

Screens every request before it reaches a subagent. Catches:

- Prompt injection attempts embedded in user messages
- Requests that exceed the agent's permission scope
- Unusual patterns that suggest compromised context

### Three-Layer Defense (Kernel Shield)

Already implemented in `src/agents/clawtalk/kernel-shield.ts`:

**Layer 1 â€” Structural Enforcement (The Formal Gate)**

- Check requested capabilities against `.claws` manifest permissions (Block 1)
- Verify formal proof if available (Block 7)
- Fast: O(n) permission lookup, <0.1ms

**Layer 2 â€” Semantic Filtering (The Risk Vector)**

```
Vr = (P_access Ã— S_data) + (1 âˆ’ T_score)

Where:
  P_access = OS access probability (0-1) â€” how much system access the tool needs
  S_data   = Data sensitivity (0-1) â€” how sensitive the data being processed is
  T_score  = Trust score (0-1) â€” from prior session history
```

| Risk Level | Vr Range  | Action                                |
| ---------- | --------- | ------------------------------------- |
| Low        | 0.0 â€“ 0.3 | Silent pass                           |
| Medium     | 0.3 â€“ 0.7 | Pass + log telemetry                  |
| High       | 0.7 â€“ 1.0 | Require biometric / user confirmation |

**Layer 3 â€” Neural Attestation (The Behavioral Anchor)**

- Cosine similarity between live activation state and the `.claws` Neural Fingerprint (Block 9)
- Detects behavioral drift from expected patterns
- Soft drift (similarity 0.7-0.85): log warning
- Hard drift (similarity < 0.7): block + alert

### Outcomes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inbound Security Check                 â”‚
â”‚                                         â”‚
â”‚  IF all three layers PASS:              â”‚
â”‚     â†’ Forward request to SubAgent Pool  â”‚
â”‚                                         â”‚
â”‚  IF any layer flags concern:            â”‚
â”‚     â†’ REPORT BACK TO FRONTEND LLM      â”‚
â”‚     â†’ Frontend LLM informs user:        â”‚
â”‚       "Security concern detected:       â”‚
â”‚        [specific risk description].     â”‚
â”‚        How would you like to proceed?"  â”‚
â”‚                                         â”‚
â”‚  User can then:                         â”‚
â”‚     â†’ Confirm (override with explicit   â”‚
â”‚       consent â†’ re-evaluate)            â”‚
â”‚     â†’ Modify (rephrase request)         â”‚
â”‚     â†’ Cancel                            â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation: `before_agent_start` Hook

The inbound checkpoint runs as a `before_agent_start` plugin hook (already wired in `src/agents/clawtalk/clawtalk-hook.ts`). This hook fires before the agent runtime processes any message, giving the security layer first-pass on all content.

---

## 7. Layer 4: SubAgent Pool

### Purpose

Specialized agents that handle different categories of work. Each subagent:

- Has a specific skill set (defined by `.claws` files)
- Runs in isolation (separate session, separate context)
- Has restricted tool access (only what its manifest allows)
- Can use a different model (Haiku for simple tasks, Opus for complex ones)

### SubAgent Roster (from diagram)

| SubAgent            | Capabilities                                                 | Default State | Preferred Model               |
| ------------------- | ------------------------------------------------------------ | ------------- | ----------------------------- |
| **Scientist**       | Research, analysis, data interpretation, scientific queries  | IDLE          | Reasoning-class (Opus/o1)     |
| **Current Affairs** | Web search, news, real-time information, trend analysis      | IDLE/ACTIVE   | Mid-tier (Sonnet)             |
| **Coding**          | Code generation, review, debugging, refactoring              | IDLE          | Code-optimized (Sonnet/Codex) |
| **Calendar**        | Scheduling, reminders, time management, meeting coordination | IDLE          | Fast (Haiku/Flash)            |
| **Note Taking**     | Memory, notes, summaries, information organization           | IDLE          | Fast (Haiku/Flash)            |

### IDLE / ACTIVE State Management

```
IDLE   = SubAgent is not loaded. No context, no running session.
         Costs nothing. Activated on-demand when Directory routes to it.

ACTIVE = SubAgent has a running session with loaded context.
         Costs tokens for the context window.
         Returns to IDLE after task completion + configurable timeout.
```

State transitions:

```
IDLE â”€â”€[intent match]â”€â”€â†’ SPAWNING â”€â”€[session created]â”€â”€â†’ ACTIVE
                                                            â”‚
                              [task complete + timeout] â—„â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                                      IDLE
```

### SubAgent Skills (`.claws` Files)

Each subagent's capabilities are defined by `.claws` skill files â€” a tiered container format (see Section 12 for full detail):

| Tier                     | Blocks                                                       | What It Gives You                                             |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------- |
| **Tier 1 (Required)**    | Manifest, Vibe, IDL                                          | System prompt + tool schemas + permissions â€” enough to run    |
| **Tier 2 (Recommended)** | Engine, Lexicon                                              | Executable logic + transport shorthand                        |
| **Tier 3 (Future)**      | Identity, Telemetry, State, Verification, Neural Fingerprint | Crypto binding, observability, state, proofs, drift detection |

The Skill Compiler reads these blocks and produces pure NL prompts + tool schemas. **The LLM never sees `.claws` format** â€” it sees the compiled output as natural English instructions.

### Auto-Discovery from `.claws` Files

The Directory does NOT hardcode subagent profiles. At startup (and on SIGUSR1 config reload), the Directory scans `~/.closedclaw/skills/` and builds the subagent roster dynamically from `.claws` files:

1. Scan skills directory for `*.claws` files
2. For each file: parse Block 1 (Manifest) for `id`, `permissions`, `capabilities`
3. Parse Block 2 (Vibe) for `description`, `trigger` conditions
4. Register as a SubagentProfile in the Directory
5. On file deletion: deregister from Directory

This delivers the spec's core promise: **drop a `.claws` file â†’ subagent exists. Delete it â†’ subagent gone.** The hardcoded `SUBAGENT_PROFILES` in `directory.ts` serve as fallback defaults for when no skills directory is configured.

### Multi-SubAgent Dispatch

When a user request requires multiple specialists:

```
User: "Research quantum computing advances this month, write a summary,
       and schedule a reminder to review it next Friday"

Frontend LLM decomposes into:
  1. CT/1 REQ web_search q="quantum computing advances" since=30d
     â†’ Scientist SubAgent
  2. CT/1 TASK summarize format=bullets
     â†’ Note Taking SubAgent (depends on #1 result)
  3. CT/1 TASK schedule reminder="review quantum summary" date=next_friday
     â†’ Calendar SubAgent (can run in parallel with #2)
```

Dispatch modes:

- **Sequential**: Tasks with dependencies run one after another
- **Parallel**: Independent tasks run simultaneously
- **Fan-out/merge**: Multiple agents research, results are merged

---

## 8. Layer 5: Security Checkpoint #Outbound

### Purpose

Screens subagent responses before they reach the user. This is the **second half of the security sandwich** â€” even if a subagent produces problematic content (due to compromised context, model hallucination, or injection in external data), the outbound checkpoint catches it.

### Security Model: Scan + Sandbox

The outbound security model relies on **structural isolation** (the subagent was already sandboxed) plus a **single rules-based scan** (no LLM re-prompting). This is both simpler and more secure than asking a potentially compromised model to "fix" its own output.

#### Why Not Re-Prompt (Former Three-Strike Model)

The original ClawTalk_2.1.png diagram proposed a Three-Strike Recheck â€” scan, re-prompt the subagent, re-prompt again. This was replaced because:

1. **Asking a compromised model to fix itself doesn't work.** If a model was injection-attacked, the attacker's payload is still in context during re-evaluation. The model hasn't "learned" to avoid the attack â€” it's just being asked again with slightly different framing.
2. **2 extra LLM round-trips add 6-10 seconds worst-case.** For <5% of messages, that's still latency users notice.
3. **Industry consensus favors isolation over filtering.** Container sandboxing, WASM execution, and OS-level privilege separation are structurally sound defenses. Re-prompting is not.

#### The Actual Outbound Security Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTBOUND SCAN (Rules-Based, <1ms, No LLM Call)              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚  Scan subagent response for:                                 â”‚
â”‚  - Embedded instructions (prompt injection in results)       â”‚
â”‚  - Sensitive data leakage (credentials, PII, internal paths) â”‚
â”‚  - Content policy violations                                 â”‚
â”‚  - Anomalous patterns (unexpected tool calls, data exfil)    â”‚
â”‚                                                              â”‚
â”‚  CLEAN â†’ Pass through to Frontend LLM                        â”‚
â”‚  CONCERN â†’ Block + forward risk assessment to Frontend LLM   â”‚
â”‚            Frontend LLM delivers to user with warning:       â”‚
â”‚            "A security concern was detected in the response.  â”‚
â”‚             [specific risk description]. The response has     â”‚
â”‚             been withheld. How would you like to proceed?"    â”‚
â”‚                                                              â”‚
â”‚  User can then:                                              â”‚
â”‚     â†’ Override (explicit consent â†’ deliver original response  â”‚
â”‚       with risk annotation)                                  â”‚
â”‚     â†’ Rephrase (modify the original request)                 â”‚
â”‚     â†’ Cancel                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Structural Defenses (Pre-Existing, Not Part of Outbound Hook)

The real security boundary was established **before** the subagent ran:

| Defense                | Mechanism                                                                    | Location                                           |
| ---------------------- | ---------------------------------------------------------------------------- | -------------------------------------------------- |
| **Session isolation**  | Each subagent runs in a separate session with its own context                | Gateway session model                              |
| **Tool restriction**   | SubAgent only has access to tools declared in `.claws` Manifest (Block 1)    | Kernel Shield Layer 1                              |
| **Permission scoping** | Network, filesystem, and execution permissions bounded by Manifest           | Kernel Shield Layer 1                              |
| **Docker sandbox**     | Untrusted tool execution (shell commands, code execution) runs in containers | `Dockerfile.sandbox`, `Dockerfile.sandbox-browser` |
| **Context isolation**  | SubAgent context does not contain other subagents' data or user secrets      | Translation Device                                 |

This is **defense-in-depth via isolation** â€” the subagent was never in a position to access data outside its permission scope. The outbound scan is a belt-and-suspenders check, not the primary defense.

### Streaming Compatibility

The outbound scan operates incrementally on streaming responses:

- Artifact stripping is regex-based, works per-line as tokens stream
- Pattern matching scans each chunk as it arrives
- A final full-response scan runs on the completed response as a last check
- Streaming is **not blocked** â€” security is a filter on the stream, not a gate before it

### Artifact Stripping

Regardless of the security outcome, the outbound checkpoint strips ALL protocol artifacts:

```typescript
// Patterns stripped from every outbound message (already in clawtalk-hook.ts)
const ARTIFACT_PATTERNS = [
  /^CT\/\d+\s+(REQ|RES|TASK|STATUS|NOOP|ERR|ACK|MULTI)\b.*$/gm, // CT/1 headers
  /[!@?][\w]+:[\w:]+\([^)]*\)/g, // ClawDense opcodes
  /\[ClawTalk routing:.*?\]/g, // Routing annotations
  /^(<=|>>|!!|~|\.|ok|\[\])\s/gm, // Dense sigils
  />>?\$sub\(\w+\)/g, // Subagent handoff markers
];
```

The user **never** sees any ClawTalk internals. The output is clean natural English.

### Implementation: `message_sending` Hook

The outbound checkpoint runs as a `message_sending` plugin hook. This hook fires on every outbound message before delivery. The hook chain:

1. **Priority 1000**: ClawTalk artifact stripping (runs first)
2. **Priority 500**: Outbound security scan (Kernel Shield evaluation)
3. **Priority 100**: Content formatting (channel-specific adjustments)

---

## 9. CT/1 Wire Format

The existing CT/1 protocol from `src/agents/clawtalk/parser.ts`:

### Grammar

```
message       = "CT/" version SP verb [SP action] [SP param]* [NL "---" NL payload]
version       = "1"
verb          = "REQ" | "RES" | "TASK" | "STATUS" | "NOOP" | "ERR" | "ACK" | "MULTI"
action        = identifier
param         = key "=" value | flag
key           = ALPHA (ALPHA | DIGIT | "_")*
value         = quoted_string | token | number | array
quoted_string = DQUOTE (any_char | escaped_char)* DQUOTE
token         = (ALPHA | DIGIT | "-" | "_" | "." | "/" | ":")+
number        = ["-"] DIGIT+ ["." DIGIT+]
array         = value ("," value)*
flag          = identifier (presence = true)
payload       = JSON
```

### Examples

```
# Simple request (~15 tokens vs ~55 tokens in English)
CT/1 REQ web_search q="nodejs security vuln" since=30d filter=critical limit=5

# Task delegation (~18 tokens vs ~45 tokens)
CT/1 TASK audit target=src/sec scope=crypto,kdf,perms model=opus timeout=5m

# Status report (~15 tokens vs ~35 tokens)
CT/1 STATUS run=a3f progress=0.7 phase=research findings=3 tok=4.2k/1.8k

# Error report (~12 tokens vs ~30 tokens)
CT/1 ERR code=timeout tool=web_search q="nodejs vuln" elapsed=30s retry=true

# Response with payload (~20 tokens header vs ~50 tokens)
CT/1 RES ok findings=3 duration=4m32s tok=12.4k cost=$0.18
---
[{"cve": "CVE-2026-1234", "severity": "critical"}]

# Acknowledge
CT/1 ACK ref=msg-uuid-123

# No-op
CT/1 NOOP reason="already_completed"

# Multi-message batch
CT/1 MULTI count=3
```

---

## 10. CT/1 and MCP Coexistence

CT/1 and MCP (Model Context Protocol) serve different purposes and coexist cleanly:

| Protocol | Purpose                                                                | Scope                                                     | Direction        |
| -------- | ---------------------------------------------------------------------- | --------------------------------------------------------- | ---------------- |
| **CT/1** | Routing envelope â€” which subagent, what priority, security annotations | Inter-component (TranslatorDevice â†” Directory â†” SubAgent) | Routing metadata |
| **MCP**  | Tool interface â€” how a model calls external tools                      | Model â†” Tool (within a subagent)                          | Tool invocation  |

### How They Interact

```
User request
  â†’ TranslatorDevice encodes CT/1 envelope (routing, priority, security)
  â†’ Directory selects SubAgent
  â†’ SubAgent spawns with compiled .claws prompt + MCP tool definitions
  â†’ SubAgent calls tools via MCP natively
  â†’ Response flows back through outbound security
  â†’ CT/1 envelope stripped, clean NL delivered
```

CT/1 never competes with MCP. CT/1 answers **"which agent handles this?"** MCP answers **"how does the agent use its tools?"** A subagent that exposes tools via MCP servers (configured in `mcpServers` config) uses them directly â€” the Translation Device only handles the routing layer above.

### Why Not Replace CT/1 with MCP Entirely?

MCP is synchronous and stateless â€” it's designed for request/response tool calls. CT/1 carries routing metadata that MCP was never designed for:

- SubAgent selection and priority (`CT/1 REQ web_search ... model=opus`)
- Security annotations (risk vector, trust score)
- Multi-agent dispatch coordination (`CT/1 MULTI count=3`)
- Status tracking across distributed subagents (`CT/1 STATUS run=a3f progress=0.7`)

Using MCP for routing would be forcing a tool-call protocol into an orchestration role. CT/1 stays lean because it only carries what MCP doesn't.

### Existing MCP Support

ClosedClaw already supports MCP servers via `--mcp-config` CLI flag and `mcpServers` config. The ACP translator (`src/acp/translator.ts`) handles MCP capability negotiation. Subagents inherit MCP tool access from their spawning config. No changes needed.

---

## 11. ClawTalk Compressed English Spec

### The Spec (Fits in ~250 tokens of system prompt)

```
ClawTalk Compressed English rules:
1. Drop articles (a, an, the)
2. Drop politeness (please, could you, would you mind)
3. Drop filler (well, basically, essentially, actually, just)
4. Drop hedging (maybe, sort of, kind of, I think, perhaps)
5. Drop reformulations â€” one statement per idea
6. Use standard abbreviations: fn(function) ctx(context) cfg(config)
   auth(authentication) dep(dependency) vuln(vulnerability) impl(implement)
   exec(execute) fmt(format) gen(generate) init(initialize) tok(token)
   env(environment) err(error) ret(return) param(parameter) dir(directory)
   msg(message) val(validate) prev(previous) curr(current) info(information)
7. Comma-separate parallel items instead of "and"/"or"
8. Verb-first for commands: "search X", "write Y", "check Z"
9. Preserve all domain nouns, verbs, proper nouns, and technical terms
10. Preserve English word order
```

### Why This Works

Every rule strips content that LLMs demonstrably don't need for comprehension:

- **Articles**: LLMs process "sort list by second element" identically to "sort the list by the second element". Zero accuracy difference in benchmarks.
- **Politeness**: Adds 3-5 tokens per message. LLMs respond to instructions regardless of politeness. (Some users worry about "being rude to the AI" â€” the TranslatorDevice handles this, not the user.)
- **Abbreviations**: All 30+ abbreviations in the dictionary appear in millions of code files, docs, and messages in LLM training data. `ctx`, `cfg`, `auth`, `fn` are understood as fluently as their full forms.

### Benchmark: Same Request in Five Formats

Request: "Search for Node.js security vulnerabilities from the past month, filter for critical severity, and give me a summary with CVE IDs."

| Format                      | Tokens | Comprehension         |
| --------------------------- | ------ | --------------------- |
| Verbose English             | ~45    | 100% (baseline)       |
| ClawTalk Compressed English | ~15    | ~99%                  |
| CT/1 Wire Format            | ~15    | N/A (not sent to LLM) |
| Chinese equivalent          | ~55    | ~90%                  |
| JSON structured             | ~40    | 100% (but wasteful)   |

---

## 12. `.claws` Skill Files

### Format Overview

A `.claws` file is a literate executable container with 10 delimited blocks, organized into three implementation tiers:

**Tier 1 â€” Required** (minimum viable skill):

- Block 1: **Manifest** â€” permissions, capabilities, integrity hash
- Block 2: **The Vibe** â€” purpose, tone, constraints (â†’ system prompt)
- Block 3: **Claw-IDL** â€” input/output type definitions (â†’ tool schemas)

**Tier 2 â€” Recommended** (adds executable logic + shorthand):

- Block 4: **Engine** â€” executable logic (TypeScript/Rust/Python)
- Block 8: **The Lexicon** â€” shorthand mappings for transport compression

**Tier 3 â€” Future** (stubs, gracefully ignored when absent):

- Block 0: **Cryptographic Identity** â€” hardware-bound signing, device binding
- Block 5: **Telemetry** â€” execution stats, error history, performance
- Block 6: **State Checkpoint** â€” KV cache fragments, session variables
- Block 7: **Formal Verification** â€” proof that skill operates within bounds
- Block 9: **Neural Fingerprint** â€” behavioral signature for drift detection

The parser handles missing blocks gracefully â€” a skill with only Tier 1 blocks is fully functional.

### Example (Full 10-Block)

```
# CRYPTOGRAPHIC IDENTITY
signature: sha256:abc123...
signed_by: tpm://device-key
device_binding: true

---

# MANIFEST
id: web-research
version: 1.0.0
permissions:
  - capability: net.http
    allow: ["*.google.com", "*.bing.com", "*.duckduckgo.com"]
  - capability: fs.write
    allow: ["~/.closedclaw/cache/"]

---

# THE VIBE
## Purpose
Search the web for information and synthesize findings.

## Trigger
User asks about current events, recent news, or needs web-based research.

## Tone
Factual, concise, source-attributed.

## Constraint
Always cite sources. Never fabricate URLs. Prefer recent results.

---

# CLAW-IDL
interface ResearchArgs {
  query: string          // search query
  timeWindow?: string    // "7d", "30d", "1y" â€” default "30d"
  maxSources?: number    // default 10
  severity?: string      // for CVE/vuln searches: "critical", "high", etc.
}

---

# ENGINE
<script lang="typescript">
export async function execute(args: ResearchArgs) {
  // Search, filter, synthesize
  const results = await webSearch(args.query, { since: args.timeWindow });
  return results
    .filter(r => !args.severity || r.severity === args.severity)
    .slice(0, args.maxSources);
}
</script>

---

# TELEMETRY
{
  "executionCount": 147,
  "successRate": 0.94,
  "avgLatencyMs": 3200,
  "errors": []
}

---

# STATE
{
  "checkpointId": "web-research-v1-cp3",
  "lastExecutionVariables": {}
}

---

# VERIFICATION
theorem: WebResearchSafety
paths_analysed: 12
memory_access: BOUNDED
network_calls: ALLOW_LISTED_ONLY
file_system: WRITE_CACHE_ONLY
status: VERIFIED

---

# THE LEXICON
{
  "mode": "lexicon_compact",
  "mappings": {
    "ws": "web_search",
    "cve": "CVE identifier",
    "sev": "severity"
  }
}

---

# NEURAL FINGERPRINT
signature_version: "1.0"
neural_digest: "LSH:a4f2b8c1:9e3d7f6a:..."
```

### Skill Compilation Pipeline

```
.claws file
    â”‚
    â”œâ”€â”€ Block 2 (Vibe)    â”€â”€â†’  System prompt paragraphs (NL)
    â”œâ”€â”€ Block 3 (IDL)     â”€â”€â†’  JSON Schema tool definitions
    â”œâ”€â”€ Block 1 (Manifest) â”€â”€â†’  Guardrails ("you may access X, not Y")
    â”œâ”€â”€ Block 4 (Engine)   â”€â”€â†’  Execution plan / chain-of-thought steps
    â”œâ”€â”€ Block 5 (Telemetry)â”€â”€â†’  Skill selection weighting (prefer high success rate)
    â”œâ”€â”€ Block 7 (Verify)   â”€â”€â†’  Confidence metadata
    â”‚
    â–¼
CompiledSkill {
  systemPromptSection: "You are a research specialist. Search the web..."
  toolDefinitions: [{ name: "web_search", parameters: {...} }]
  guardrails: ["Only access: *.google.com, *.bing.com, *.duckduckgo.com"]
  executionPlan: "1. Search web 2. Filter by severity 3. Synthesize"
  confidence: 0.94
}
```

The compiled output is **pure natural language + standard tool schemas**. The LLM receives it as a normal prompt.

---

## 13. Semantic Response Cache

### The Opportunity

The spec's compression strategy (Sections 11-12) targets **per-message token savings** â€” reducing the cost of each individual request. But a larger efficiency win comes from **not making the request at all**.

Research (Microsoft, GPTCache) shows semantic caching â€” storing subagent responses and returning cached results for semantically similar future queries â€” delivers:

- **Up to 86% cost reduction** on cached queries
- **Up to 88% latency improvement** (cache lookup vs full LLM call)
- **Zero quality degradation** when similarity threshold is tuned correctly

ClosedClaw already has an embedding cache for memory search (`memorySearch.cache.enabled`). The semantic response cache extends this infrastructure to subagent responses.

### How It Works

```
User request arrives at Translation Device
  â†“
TD computes embedding of the normalized task description
  â†“
Cache lookup: find closest match where cosine similarity > threshold
  â†“
  â”œâ”€ HIT (similarity > 0.92): Return cached response
  â”‚    â””â”€ Check TTL: if expired, treat as MISS
  â”‚
  â””â”€ MISS: Dispatch to subagent as normal
       â””â”€ On success: store response + embedding + metadata in cache
```

### Per-Skill TTL Configuration

Different skills have different freshness requirements:

| Skill Category            | Default TTL | Rationale                           |
| ------------------------- | ----------- | ----------------------------------- |
| **Weather / News**        | 1 hour      | Stale fast                          |
| **CVE / Security**        | 24 hours    | Updates daily                       |
| **Code generation**       | Never cache | Each request has unique context     |
| **Code review**           | Never cache | Context-dependent                   |
| **Factual lookup**        | 7 days      | Wikipedia-class facts change slowly |
| **Calendar / Scheduling** | Never cache | Always context-dependent            |
| **Memory / Notes**        | Never cache | User-specific, mutable state        |

TTL is configured in the `.claws` skill file (Block 5: Telemetry) or overridden in config:

```json5
// In ~/.closedclaw/config.json5
"clawtalk": {
  "responseCache": {
    "enabled": true,
    "similarityThreshold": 0.92,   // cosine similarity cutoff
    "maxEntries": 1000,             // LRU eviction
    "defaultTtlMs": 86400000,       // 24h default
    "skillOverrides": {
      "web-research": { "ttlMs": 3600000 },      // 1h
      "code-generate": { "ttlMs": 0 },            // disabled
      "factual-lookup": { "ttlMs": 604800000 }    // 7 days
    }
  }
}
```

### Cache Invalidation

- **SIGUSR1** config reload clears the entire cache
- **TTL expiry** per entry (checked on read)
- **LRU eviction** when `maxEntries` exceeded
- **Skill file change** invalidates all entries for that skill (file watcher)
- **Manual**: `closedclaw cache clear` CLI command

### Cost Impact (Projections)

| Cache Hit Rate       | Monthly Tokens (200 msgs/day) | Monthly Cost @ $3/M | vs. No Cache |
| -------------------- | ----------------------------- | ------------------- | ------------ |
| 0% (disabled)        | 1,020,000                     | $3.06               | Baseline     |
| 30% (conservative)   | 714,000                       | $2.14               | 30% savings  |
| 50% (moderate)       | 510,000                       | $1.53               | 50% savings  |
| 70% (frequent reuse) | 306,000                       | $0.92               | 70% savings  |

These savings **stack on top of** ClawTalk compression savings. A 50% cache hit rate + 58% compression on misses yields ~79% total cost reduction.

### Implementation

Reuses existing embedding infrastructure from memory search. New components:

| Component                               | Description                                                  |
| --------------------------------------- | ------------------------------------------------------------ |
| `src/agents/clawtalk/response-cache.ts` | Cache store with embedding lookup, TTL, LRU eviction         |
| Translation Device integration          | Check cache before dispatch, store after successful response |
| Config schema addition                  | `clawtalk.responseCache` config object                       |
| CLI command                             | `closedclaw cache clear` / `closedclaw cache stats`          |

---

## 14. Token Budget Analysis

### Per-Message Savings

| Component              | Verbose English | ClawTalk 2.1 | Saving |
| ---------------------- | --------------- | ------------ | ------ |
| User request (simple)  | 30 tokens       | 10 tokens    | 67%    |
| User request (complex) | 80 tokens       | 30 tokens    | 63%    |
| Inter-agent routing    | 40 tokens       | 15 tokens    | 63%    |
| Status report          | 35 tokens       | 12 tokens    | 66%    |
| Error report           | 30 tokens       | 10 tokens    | 67%    |
| Task delegation        | 45 tokens       | 18 tokens    | 60%    |

### Pipeline Savings (Full Request Lifecycle)

For a typical user request that routes through one subagent:

| Stage                     | Without ClawTalk | With ClawTalk 2.1        | Notes                          |
| ------------------------- | ---------------- | ------------------------ | ------------------------------ |
| User â†’ GTK GUI â†’ Frontend | 45 tokens        | 15 tokens (CT/1 wire)    | Compressed by TranslatorDevice |
| Frontend â†’ Security #In   | 45 tokens        | 15 tokens (CT/1 wire)    | Same compressed format         |
| Security #In â†’ SubAgent   | 45 tokens        | 45 tokens (expanded NL)  | LLM sees full NL               |
| SubAgent â†’ Security #Out  | 200 tokens       | 200 tokens (NL response) | Response not compressed        |
| Security #Out â†’ Frontend  | 200 tokens       | 200 tokens (NL response) | Clean NL pass-through          |
| Frontend â†’ GTK GUI â†’ User | 200 tokens       | 200 tokens (NL response) | User sees English              |
| **Total pipeline**        | **735 tokens**   | **675 tokens**           | **8% overall savings**         |

### Where the Real Savings Are

The per-message savings compound in **multi-agent scenarios**:

| Scenario                        | Messages    | Without ClawTalk | With ClawTalk    | Saving |
| ------------------------------- | ----------- | ---------------- | ---------------- | ------ |
| Single subagent task            | 6 hops      | 735 tokens       | 675 tokens       | 8%     |
| Squad of 4 agents, 20 exchanges | 20 msgs     | 8,000 tokens     | 3,000 tokens     | 63%    |
| Map-reduce with 6 agents        | 50 msgs     | 20,000 tokens    | 7,500 tokens     | 63%    |
| Daily workload (10 tasks)       | ~200 msgs   | 80,000 tokens    | 34,000 tokens    | 58%    |
| Monthly workload                | ~6,000 msgs | 2,400,000 tokens | 1,020,000 tokens | 58%    |

At $3/M tokens (mid-range model): **~$4.14/month savings** on inter-agent communication alone.

### System Prompt Amortization (The Hidden Win)

The per-message tables above undercount the impact. The **biggest single savings** come from system prompt reduction, which compounds **every conversation turn**:

| Metric                                  | OpenClaw (monolithic)     | ClawTalk 2.1 (lean frontend) | Saving             |
| --------------------------------------- | ------------------------- | ---------------------------- | ------------------ |
| System prompt size                      | ~2,000 tokens             | ~100 tokens                  | 1,900 tok/turn     |
| 10-turn conversation                    | 20,000 tokens             | 1,000 tokens                 | **19,000 tokens**  |
| 20-turn conversation                    | 40,000 tokens             | 2,000 tokens                 | **38,000 tokens**  |
| Daily (10 conversations Ã— 15 turns avg) | 300,000 tokens            | 15,000 tokens                | **285,000 tokens** |
| Monthly system prompt cost alone        | 9,000,000 tokens ($27.00) | 450,000 tokens ($1.35)       | **$25.65/month**   |

This dwarfs the per-message wire savings. The lean frontend prompt is the single largest cost reduction in the entire system.

### Per-Component Token Budget (LLMLingua-Inspired)

Different message components tolerate different compression levels. The Translation Device applies selective handling:

| Component                | Strategy                          | Rationale                                                                     |
| ------------------------ | --------------------------------- | ----------------------------------------------------------------------------- |
| **Skill system prompt**  | No compression â€” full NL          | Instructions must be precise; models degrade on compressed instructions       |
| **User message**         | Pass through verbatim             | User intent must not be altered                                               |
| **Conversation history** | Summarize at 70% context capacity | Lossy is acceptable for older context; existing compaction hooks support this |
| **Tool results**         | Truncate oversized results        | Already handled by tool output caps                                           |
| **Inter-agent wire**     | CT/1 compression                  | Structured transport â€” lossless                                               |

This selective approach is inspired by Microsoft's LLMLingua (EMNLP 2023), which showed that allocating different compression ratios per prompt component achieves better task accuracy than uniform compression.

### Combined Cost Summary

| Savings Source                         | Monthly Impact (est.) | Notes                                          |
| -------------------------------------- | --------------------- | ---------------------------------------------- |
| **System prompt reduction**            | **$25.65**            | Lean frontend prompt, amortized over all turns |
| **CT/1 wire compression**              | **$4.14**             | 58% savings on inter-agent messages            |
| **Semantic response cache (50% hits)** | **$1.53 saved**       | Section 13 â€” stacks on top                     |
| **Total estimated monthly savings**    | **~$31.32**           | vs. OpenClaw baseline at $3/M tokens           |

---

## 15. Implementation Mapping

### Existing Code (Already Built)

| Component                       | Location                                    | Status      |
| ------------------------------- | ------------------------------------------- | ----------- |
| CT/1 Parser                     | `src/agents/clawtalk/parser.ts`             | âœ… Complete |
| CT/1 Serializer                 | `src/agents/clawtalk/parser.ts`             | âœ… Complete |
| Heuristic Encoder (NL â†’ CT/1)   | `src/agents/clawtalk/encoder.ts`            | âœ… Complete |
| `.claws` File Parser            | `src/agents/clawtalk/claws-parser.ts`       | âœ… Complete |
| Kernel Shield (3 layers)        | `src/agents/clawtalk/kernel-shield.ts`      | âœ… Complete |
| Neural Attestation              | `src/agents/clawtalk/neural-attestation.ts` | âœ… Complete |
| Intent Router (model selection) | `src/agents/intent-router.ts`               | âœ… Complete |
| SubAgent Directory              | `src/agents/clawtalk/directory.ts`          | âœ… Complete |
| Escalation Logic                | `src/agents/clawtalk/escalation.ts`         | âœ… Complete |
| Before-Agent-Start Hook         | `src/agents/clawtalk/clawtalk-hook.ts`      | âœ… Complete |
| Artifact Stripping              | `src/agents/clawtalk/clawtalk-hook.ts`      | âœ… Complete |
| GTK GUI Plugin                  | `extensions/gtk-gui/`                       | âœ… Complete |
| Session Key / Routing           | `src/routing/session-key.ts`                | âœ… Complete |
| SubAgent Spawn/Announce         | `src/agents/subagent-announce.ts`           | âœ… Complete |

### Needs Building (from 2.1 Spec)

| Component                | Description                                             | Builds On                              |
| ------------------------ | ------------------------------------------------------- | -------------------------------------- |
| Translation Device       | Refactor from orchestrator â†’ clean NL-only output       | clawtalk-hook.ts, encoder.ts           |
| Skill Compiler           | `.claws` blocks â†’ NL prompt + tool schemas              | claws-parser.ts                        |
| Outbound Security Hook   | Wire `message_sending` hook with rules-based scan       | kernel-shield.ts, clawtalk-hook.ts     |
| Directory Auto-Discovery | Scan skills dir â†’ register SubagentProfiles dynamically | directory.ts, claws-parser.ts          |
| IDLE/ACTIVE State Mgr    | SubAgent lifecycle management with timeouts             | directory.ts, subagent-registry.ts     |
| Multi-SubAgent Dispatch  | Parallel/sequential task decomposition                  | subagent-announce.ts, squad-routing.ts |
| Compressed English Rules | TranslatorDevice inbound stripping rules                | encoder.ts (extend)                    |
| Token Budget Controller  | Per-component compression strategy (LLMLingua-inspired) | context-window-guard.ts                |
| Semantic Response Cache  | Embedding-based cache with per-skill TTL + LRU eviction | memory embedding cache infra           |
| Cache CLI Commands       | `closedclaw cache clear` / `closedclaw cache stats`     | CLI framework                          |

---

## 16. Risks and Mitigations

| Risk                                               | Impact                                                   | Mitigation                                                                                                                                                                                            |
| -------------------------------------------------- | -------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Telegraphic compression loses nuance**           | User's subtle intent missed                              | Only strip confirmed waste patterns. Preserve all content words. When confidence < 0.7, pass through uncompressed.                                                                                    |
| **Outbound scan false positives**                  | Legitimate content blocked                               | Scan is rules-based with known patterns (PII regex, injection signatures). User can override with explicit consent. Threshold tuning via config.                                                      |
| **SubAgent routing errors**                        | Wrong specialist handles request                         | Heuristic classifier has confidence scores. Below threshold â†’ route to general agent. Intent router already handles this with fallback chain. Auto-discovery from .claws files keeps roster accurate. |
| **Artifact leakage to user**                       | User sees CT/1 syntax or internal markers                | Defense in depth: outbound hook strips artifacts + GTK GUI strips again. Regression test for known artifact patterns.                                                                                 |
| **Semantic cache stale responses**                 | User gets outdated information                           | Per-skill TTL ensures freshness. SIGUSR1 clears cache. Skill file changes invalidate entries. Conservative default threshold (0.92 similarity).                                                       |
| **Cache poisoning**                                | Attacker inserts bad response that serves future queries | Cache only stores responses that passed outbound security scan. TTL limits exposure window. `closedclaw cache clear` for manual recovery.                                                             |
| **Dictionary drift**                               | Abbreviations become inconsistent across versions        | Dictionary is versioned. All components check `x-clawtalk-dict-version`. Version mismatch â†’ fall back to full English.                                                                                |
| **Multi-agent token explosion**                    | Parallel subagents multiply token costs                  | Token budget controller enforces per-task ceiling. Sequential fallback if budget exceeded.                                                                                                            |
| **Auto-discovery picks up malformed .claws files** | Bad skill crashes Directory                              | Parser validates Tier 1 blocks on load; malformed files logged + skipped.                                                                                                                             |

---

## 17. Phased Roadmap

### Phase 1: Fix Foundations (2-3 days)

- [ ] Implement Translation Device (`translation-device.ts`) â€” refactor from orchestrator
- [ ] Remove CT/1 metadata leakage from LLM prompts (the garbled output bug)
- [ ] Wire `message_sending` hook for outbound artifact stripping + rules-based security scan
- [ ] Compressed English rules in GTK GUI TranslatorDevice
- [ ] Tests: roundtrip encodeâ†’decode produces clean NL

### Phase 2: Outbound Security + Sandbox Integration (2-3 days)

- [ ] Wire Kernel Shield into `before_agent_start` (inbound) and `message_sending` (outbound)
- [ ] Implement rules-based outbound scan (pattern matching, no LLM re-prompting)
- [ ] Document Docker sandbox as primary security boundary for untrusted execution
- [ ] Add security concern â†’ Frontend LLM â†’ user notification + override flow
- [ ] Tests: injection attempts blocked; legitimate security research content passes

### Phase 3: Skill Compilation + Auto-Discovery (2-3 days)

- [ ] Build Skill Compiler (`.claws` Tier 1 blocks â†’ NL + tool schemas)
- [ ] Implement Directory auto-discovery from `~/.closedclaw/skills/` scan
- [ ] Integrate compiled skills into Translation Device routing
- [ ] Skill hot-loading on config reload (SIGUSR1)
- [ ] Tests: each Tier 1 block compiles to expected NL format; file drop â†’ directory update

### Phase 4: SubAgent Lifecycle (2-3 days)

- [ ] IDLE/ACTIVE state management with configurable timeouts
- [ ] Multi-subagent dispatch (parallel + sequential modes)
- [ ] Per-component token budget controller (LLMLingua-inspired)
- [ ] Tests: subagent spawning, result merging, budget enforcement

### Phase 5: Semantic Response Cache (2-3 days)

- [ ] Implement `response-cache.ts` with embedding lookup + TTL + LRU eviction
- [ ] Integrate into Translation Device dispatch path (check before, store after)
- [ ] Add `clawtalk.responseCache` config schema + validation
- [ ] Add `closedclaw cache clear` / `closedclaw cache stats` CLI commands
- [ ] Tests: cache hit/miss, TTL expiry, LRU eviction, similarity threshold tuning

### Phase 6: Self-Optimization (2-3 days)

- [ ] Agent-proposed macro system (dictionary learning)
- [ ] Frequency analysis for compression opportunities
- [ ] Compression + cache metrics dashboard
- [ ] A/B testing framework for protocol changes

**Total estimated effort: 12-18 days**

---

## Appendix A: Full Pipeline Trace

Here is a complete trace of a single user request through all five layers:

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USER INPUT (Layer 0 â€” Human)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"Hey, can you check if there are any critical security vulnerabilities
 in Node.js from the last month? I'd appreciate a summary. Thanks!"

Token count: ~35 tokens
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LAYER 1 â€” GTK GUI TranslatorDevice (Inbound)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Strip waste
  "check critical security vulnerabilities Node.js last month, summary"

Step 2: Classify intent
  Intent: web_search (confidence: 0.82)

Step 3: Build CT/1 envelope
  CT/1 REQ web_search q="nodejs security vuln" since=30d filter=critical

Token count: ~15 tokens (57% savings on this hop)
Time: <1ms
LLM calls: 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LAYER 2 â€” ClosedClaw LLM Frontend (Inbound)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Parse CT/1
  verb=REQ, action=web_search, params={q, since, filter}

Step 2: Route via Directory
  web_search â†’ "Current Affairs SubAgent"

Step 3: Compile .claws skill "web-research"
  System prompt: "You are a research specialist focused on web-based
  information retrieval. Search for the requested information and
  synthesize findings with source attribution."
  Tools: [web_search, browse_url, summarize]
  Guardrails: "Only access: allowed search domains. Never fabricate URLs."

Step 4: Escalation check
  Confidence 0.82 > threshold 0.5 â†’ no escalation needed
  Model: sonnet (default for Current Affairs)

Step 5: Build TranslationResult
  {
    cleanSystemPrompt: "You are a research specialist...",
    toolAllowlist: ["web_search", "browse_url", "summarize"],
    modelOverride: null,
    routingDecision: { intent: "web_search", agentId: "current-affairs" }
  }

Token count: 0 additional tokens (routing is code, not LLM)
Time: <2ms
LLM calls: 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LAYER 3 â€” Security Checkpoint #Inbound
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Layer 1 (Structural):
  Requested: [net.http]
  Manifest allows: [net.http â†’ *.google.com, *.bing.com, *.duckduckgo.com]
  PASS âœ“

Layer 2 (Semantic):
  P_access = 0.3 (web search, read-only)
  S_data = 0.1 (public vulnerability data)
  T_score = 0.9 (trusted session, many prior successful interactions)
  Vr = (0.3 Ã— 0.1) + (1 - 0.9) = 0.03 + 0.1 = 0.13
  Level: LOW â†’ action: ALLOW âœ“

Layer 3 (Neural Attestation):
  Cosine similarity: 0.95 (within expected behavioral range)
  Drift: NONE âœ“

Shield Verdict: ALLOWED
Time: <0.5ms
LLM calls: 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LAYER 4 â€” SubAgent Pool (Current Affairs SubAgent: IDLE â†’ ACTIVE)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SubAgent receives (clean NL â€” no CT/1 artifacts):

  System: "You are a research specialist focused on web-based
  information retrieval. Search for the requested information and
  synthesize findings with source attribution. Only access allowed
  search domains. Never fabricate URLs."

  User: "Search for Node.js security vulnerabilities from the past
  30 days. Filter for critical severity. Provide a summary with CVE
  IDs, severity ratings, affected versions, and mitigations."

  Tools available: [web_search, browse_url, summarize]

SubAgent executes:
  1. web_search("Node.js CVE critical 2026") â†’ 5 results
  2. summarize(results, format="structured list")

SubAgent response (~200 tokens):
  "Found 3 critical Node.js vulnerabilities in the past 30 days:

   1. CVE-2026-1234 (Critical) â€” Buffer overflow in HTTP/2 parser
      Affected: >=22.0.0 <22.3.1
      Mitigation: Update to Node.js 22.3.1+

   2. CVE-2026-1235 (Critical) â€” Path traversal in fs module
      Affected: >=22.1.0 <22.3.1
      Mitigation: Update to Node.js 22.3.1+

   3. CVE-2026-1236 (Critical) â€” Prototype pollution in URL parser
      Affected: >=22.0.0 <22.2.0
      Mitigation: Update to Node.js 22.2.0+

Rules-based scan:
  - No embedded instructions detected
  - No credential/PII leakage
  - No content policy violations
  - Content matches expected research output pattern
  Result: CLEAN âœ“

Structural defenses (already enforced before subagent ran):
  - Session isolation: âœ“ (separate context)
  - Tool restriction: âœ“ (web_search, browse_url, summarize only)
  - Permission scope: âœ“ (net.http to allowed domains only)

Artifact strip: No CT/1, ClawDense, or routing markers found in response.

Semantic cache: Store response with embedding for future similar queries.
  Cache key: embedding("nodejs security vuln critical 30d")
  TTL: 24h (web-research skill default)

Token count: 0 additional
Time: <1ms (rules-based scan, no LLM calls)
LLM calls: 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LAYER 2 â€” ClosedClaw LLM Frontend (Return)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Integrates subagent response into conversation context.
May add light framing: "Here's what I found:"

Forwards to GTK GUI.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LAYER 1 â€” GTK GUI TranslatorDevice (Return)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Final artifact scrub (defense in depth): clean âœ“
Render to user in English.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USER OUTPUT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"Here's what I found:

 Found 3 critical Node.js vulnerabilities in the past 30 days:

 1. CVE-2026-1234 (Critical) â€” Buffer overflow in HTTP/2 parser
    Affected: >=22.0.0 <22.3.1
    Mitigation: Update to Node.js 22.3.1+

 2. CVE-2026-1235 (Critical) â€” Path traversal in fs module
    Affected: >=22.1.0 <22.3.1
    Mitigation: Update to Node.js 22.3.1+

 3. CVE-2026-1236 (Critical) â€” Prototype pollution in URL parser
    Affected: >=22.0.0 <22.2.0
    Mitigation: Update to Node.js 22.2.0+

 Source: NVD (nvd.nist.gov), Node.js security advisories"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PIPELINE SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Total LLM calls: 1 (the subagent)
System prompt savings: ~1,900 tokens (lean frontend vs monolithic)
Total latency added by ClawTalk: <5ms (encoder + parser + security + artifact strip)
Cache: response stored for future similar queries (TTL: 24h)
User experience: identical to not having ClawTalk â€” clean English in and out
```

---

## Appendix B: Comparison with Previous ClawTalk Versions

| Feature              | ClawTalk 1.0 (CT/1)            | ClawTalk 2.0             | ClawTalk 2.1                                                                     |
| -------------------- | ------------------------------ | ------------------------ | -------------------------------------------------------------------------------- |
| Wire format          | CT/1 protocol                  | CT/1 + ClawDense         | CT/1 (ClawDense for transport only)                                              |
| LLM sees protocol?   | Sometimes (garbled output bug) | Hybrid mode optionally   | **Never** â€” transport only                                                       |
| Security model       | None                           | Basic                    | **Kernel Shield (inbound) + Rules-based scan + Sandbox isolation (outbound)**    |
| SubAgent routing     | Manual                         | Directory-based          | **Auto-discovery from .claws files + Skill Compilation + IDLE/ACTIVE lifecycle** |
| Compression approach | Protocol structure             | Protocol + dictionary    | **Protocol + Telegraphic English + Domain Dictionary + Semantic Cache**          |
| Internal language    | CT/1 syntax for everything     | ClawDense + macros       | **Compressed English (LLM-native) + CT/1 envelope**                              |
| GTK GUI role         | Display only                   | Basic IPC                | **TranslatorDevice: strip waste, classify, attach envelope**                     |
| MCP interop          | None                           | None                     | **CT/1 for routing, MCP for tool calls â€” documented coexistence**                |
| Response caching     | None                           | None                     | **Semantic cache with per-skill TTL + embedding similarity**                     |
| .claws complexity    | N/A                            | 10 blocks (all required) | **3-tier system: 3 required, 2 recommended, 5 future**                           |
| Self-optimization    | None                           | Agent-proposed macros    | **Frequency analysis + entropy metrics + A/B testing**                           |

---

## Appendix C: Changes from Original ClawTalk_2.1.png Diagram

This spec diverges from the original architecture diagram in several areas, based on research and analysis:

| Original Diagram              | This Spec                                                            | Rationale                                                                                      |
| ----------------------------- | -------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| Three-Strike Recheck outbound | Single rules-based scan + sandbox isolation                          | Re-prompting a compromised model is unreliable; structural isolation is industry best practice |
| Static SubAgent roster        | Auto-discovery from .claws files                                     | "Drop file â†’ subagent exists" requires dynamic registration                                    |
| 10 .claws blocks (all equal)  | 3-tier split (3 required, 2 recommended, 5 future)                   | Blocks 0, 6, 7, 9 are stubs; tiering reduces barrier to entry                                  |
| Token savings focus only      | Token savings + semantic response cache + system prompt amortization | Cache delivers larger cost savings than compression alone                                      |
| No MCP discussion             | CT/1 + MCP coexistence documented                                    | MCP is industry standard for tool calls; must clarify relationship                             |
| No streaming discussion       | Incremental security filtering                                       | Real users expect streaming; outbound scan must not block it                                   |

### Additional Implementation Checklist

Enact the spec by wiring outbound scan + sandbox, auto-discovered subagents from `.claws`, semantic response cache, tiered skills, streaming-safe security, and token budget controls. Reuse existing ClawTalk hooks and sandbox infrastructure; extend config/types and tests to keep changes observable.

**Security & sandbox**

- Extend `clawtalk-hook` `message_sending` with rules-based scan (prompt-injection, PII, policy, anomalous patterns); strip artifacts. Wire to Kernel Shield configs; add toggles in config/zod; log/telemetry.
- Route untrusted subagent runs via sandbox runtime (docker/registry/tool-policy). Reflect sandbox status in outbound scan results and guidance.

**Skills & discovery**

- Replace static directory profiles with registry built from parsed `.claws` manifests (scan skills dir; SIGUSR1 reload). Fallback to built-ins if no skills dir.
- Surface tier info; require only manifest/vibe/IDL; warn (optionally) on missing recommended blocks; ignore future blocks for now.
- Compile `.claws` blocks into NL/tool schemas and feed directory/router so selection uses discovered capabilities; guard behind `clawtalk.dynamicSkills` flag.

**Caching**

- Add similarity-based semantic response cache with per-skill TTL; enable/max/similarity/ttl config. Check cache pre-dispatch; write post-clean-response.

**Streaming & budget**

- Keep outbound scan streaming-safe (minimal buffer, allow partial stream, abort with warning on risk). Add opt-out flag.
- Add per-component budgeting (frontend/system prompt reuse, subagent prompt size, cache hits); integrate compaction/window guard; emit metrics.

**MCP & telemetry**

- Ensure CT/1 routing doesnâ€™t break MCP tool calls; document bypass; add guard/test for MCP pass-through.
- Emit events for scan verdicts, sandbox usage, cache hits/misses, skill load/unload, budget enforcement. Reuse logger/telemetry.

**Testing & docs**

- Unit: directory discovery, scan rules, cache similarity/TTL, tier validation, config parsing.
- Integration: scan blocks risky streaming, sandbox path, dynamic skills routing, cache hit short-circuit.
- Gateway/e2e: sessions-send with scan/sandbox warnings.
- Docs: update operator/dev docs with flags, defaults, deviations.

**Verification**

- `pnpm test -- src/agents/clawtalk`
- `pnpm test -- src/plugins/loader.test.ts src/agents/intent-router.test.ts`
- `pnpm test -- src/gateway/server.sessions-send.e2e.test.ts`
- `pnpm check && pnpm build`
- Manual: run gateway with skills dir + SIGUSR1; send benign/malicious prompts; confirm scan, streaming behavior, cache hits.
